# Information Theory in Deep Learning
This repository contains implementations (mostly in PyTorch), relevant resources and lessons related to information theory of deep learning.

## Resources

### Videos and Talks

- [Stanford Seminar - Information Theory of Deep Learning, Dr. Naftly Tishby, 2018](https://www.youtube.com/watch?v=XL07WEc2TRI)
- [Information Theory of Deep Learning (Yandex) - Naftali Tishby, 2017](https://www.youtube.com/watch?v=dPhsU0bu4LY)

### Research Papers

[1] [Naftali Tishby and Noga Zaslavsky. “Deep learning and the information bottleneck principle” IEEE Information Theory Workshop (ITW), 2015](https://arxiv.org/pdf/1503.02406.pdf)

[2] [Ravid Schwartz-Ziv and Naftali Tishby. “Opening the Black Box of Deep Neural Networks via Information” ICRI-CI, 2017](https://arxiv.org/pdf/1703.00810.pdf)

[3] [Naftali Tishby, Fernando C. Pereira, and William Bialek. "The information bottleneck method"](https://arxiv.org/pdf/physics/0004057.pdf)

[4] [Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, R Devon Hjelm, "Mutual Information Neural Estimation" ICML, 2018](https://arxiv.org/abs/1801.04062)

[5] [Ben Poole, Sherjil Ozair, Aaron van den Oord, Alexander A. Alemi, George Tucker1, "On variational lower bounds of mutual information", NeurIPS, 2018](http://bayesiandeeplearning.org/2018/papers/136.pdf)

### Blog posts and Articles

- [Lilian Weng’s blog post: Anatomize Deep Learning using Information Theory, Sep 2017](https://lilianweng.github.io/lil-log/2017/09/28/anatomize-deep-learning-with-information-theory.html)
- [My own blog post on Information Theory of Deep Learning, Dec 2018](https://adityashrm21.github.io/Information-Theory-In-Deep-Learning/)
